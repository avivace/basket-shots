\section{Creazione del training set}

Il primo passo effettivo, quindi, è stato il preprocessing dei dati. I valori nulli di ciascun attributo erano stati rimossi durante l’integrazione. È da verificare, invece, la presenza di valori inconsistenti nel dominio dell’attributo preso in considerazione.
Ad esempio, per \textit{touch time} sono stati trovati valori non positivi. Considerando che questo attributo rappresenta periodi di tempo non nulli e minori di 24 secondi, valori non negativi non sono ammessi e sono stati rimossi.
Non sono stati trovati altri attributi con valori anomali.

\par
È stata poi stata applicata una normalizzazione del dataset per gli attributi numerici. È un procedimento che viene applicato frequentemente perché gli attributi sono calcolati con unità di misura differenti. In questo modo si evita che un attributo abbia un peso maggiore di un altro. È stato utilizzato per ciascun attributo il metodo
$$ \text{(min max)}\quad x = \dfrac{x - min(x)}{max(x) - min(x)} $$ 
molto utilizzato in letteratura in alternativa a
$$\text{(z score)}\quad x = \dfrac{x - \mu}{\sigma} $$
 in quanto gli attributi sono limitati in un range. Con $min max$ i valori di ciascun attributo vengono posti tra 0 e 1.

\par
Non essendo SVM una tecnica che gestisce attributi categorici, è stata applicata una tecnica di \textit{one-hot encoding} per gestirli. In questo modo vengono creati tanti nuovi attributi quante sono le categorie di ciascun attributo. Il nuovo attributo è 1 se l’attributo originale aveva quel determinato valore, 0 altrimenti.