\section{Creazione del training set}

Il primo passo effettivo, quindi, è stato il preprocessing dei dati. I valori \texttt{null} di ciascun attributo erano stati prontamente rimossi durante l’integrazione. È da verificare, invece, la presenza di valori inconsistenti nel dominio dell’attributo preso in considerazione.
Ad esempio, per l’attributo \texttt{touch\_time} sono stati trovati valori $\leq$ 0. Considerando che il dominio di \texttt{touch\_time} è $[0, 24]$, valori $\leq 0$ non sono ammessi, e vengono quindi eliminati dal dataset i record con tale valore di \texttt{touch\_time}. Non sono stati trovati altri attributi con valori anomali.

\par
Successivamente è stata applicata una normalizzazione del dataset per gli attributi numerici. È un procedimento che viene applicato frequentemente perché gli attributi sono calcolati con unità di misura differenti. In questo modo si evita che un attributo abbia un peso maggiore di un altro. È stato utilizzato per ciascun attributo il metodo
$$ \text{(min max)}\quad x = \dfrac{x - min(x)}{max(x) - min(x)} $$ 
molto utilizzato in letteratura in alternativa a
$$\text{(z score)}\quad x = \dfrac{x - \mu}{\sigma} $$
 in quanto gli attributi sono limitati in un range. Con la formula min-max i valori di ciascun attributo vengono posti tra 0 e 1.

\par
Non essendo SVM una tecnica che gestisce attributi categorici, è stata applicata una tecnica di one-hot encoding per gestirli. In questo modo vengono creati tanti nuovi attributi quante sono le categorie di ciascun attributo. Il nuovo attributo è 1 se l’attributo originale aveva quel determinato valore, 0 altrimenti.